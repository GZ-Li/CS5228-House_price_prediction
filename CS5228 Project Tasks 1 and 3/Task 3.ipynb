{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6044f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c063cb2-9263-4362-b268-faa09ac87594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill na with the nearest data or data from the same subzone\n",
    "def min_dist_feature_in_same_subzone (fill_in_feature, subzone, lat, lng, df):\n",
    "    df_subset = df[df['subzone'] == subzone]\n",
    "    df_subset = df_subset.reset_index(drop=True)\n",
    "    return df.iloc[np.argmin(np.sqrt((df[\"lat\"]-lat)**2+(df[\"lng\"]-lng)**2))][fill_in_feature]\n",
    "\n",
    "def fill_NA_with_nearest_record(df, empty_feature):\n",
    "    df_empty = df[(df[empty_feature].isna())]\n",
    "    df_empty[empty_feature] = df_empty.apply(lambda row: min_dist_feature_in_same_subzone(empty_feature, row['subzone'], row['lat'], row['lng'], df[(df[empty_feature].notna())]), axis=1)\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_type: First character uppercase -> lowercase\n",
    "df_train['property_type'] = df_train['property_type'].str.lower()\n",
    "\n",
    "# property_type: (hdb 2 rooms, hdb 3 rooms, hdb 4 rooms, hdb 5 rooms) -> hdb\n",
    "temp = df_train['property_type'].str.startswith(('hdb 2', 'hdb 3', 'hdb 4', 'hdb 5'))\n",
    "df_train['property_type'] = np.where((temp == True), 'hdb', df_train['property_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb71b3-b442-4010-aa63-d96998a59cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_beds: fill 1 with studio\n",
    "df_train['num_beds'] = np.where((df_train['num_beds'].isna() & df_train['title'].str.startswith('studio ')), \n",
    "                                1, df_train['num_beds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301a5bc-01d7-4982-a759-e111e0d9f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price: delete rows with price value 0\n",
    "df_train = df_train[df_train['price'] != 0]\n",
    "\n",
    "# subzone & planning_area: delete rows with subzone and planning_area values NaN \n",
    "df_train = df_train[(df_train['subzone'].notna() & df_train['planning_area'].notna())]\n",
    "\n",
    "# tenure: fill all hdb property_type with hdb defult tenure value - '99-year-leasehold'\n",
    "hdb_tenure = df_train[(df_train['property_type'].str.startswith('hdb')) & df_train['tenure'].notna() ]['tenure'].unique()[0]\n",
    "df_train['tenure'] = np.where((df_train['property_type'].str.startswith('hdb')) & (df_train['tenure'].isna()), hdb_tenure, df_train['tenure'])\n",
    "\n",
    "# tenure: fill in NaN tenure with value from same property_name, otherwise drop\n",
    "df_train.tenure = df_train.groupby('property_name').tenure.transform('first')\n",
    "\n",
    "# tenure: delete rows with tenure values NaN as no useful records can be used to fill in NaN values\n",
    "df_train = df_train[df_train['tenure'].notna()]\n",
    "\n",
    "# built_year: fill in NaN built_year with value from same property_name, otherwise drop\n",
    "df_train.built_year = df_train.groupby('property_name').built_year.transform('first')\n",
    "\n",
    "df_train = df_train[df_train['built_year'].notna()]\n",
    "\n",
    "df_train['lease_end_year'] = df_train.tenure.str.extract('(\\d+)')\n",
    "df_train['lease_end_year'] = np.where((df_train['tenure'] == 'freehold'), 9999, df_train['lease_end_year'])\n",
    "df_train['lease_end_year'] = np.where((df_train['tenure'] == 'freehold'), 9999, df_train['lease_end_year'].astype(int) + df_train.built_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432fd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete the data with unreasonable size\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Reset index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "# Remove NaN in num_beds and num_baths\n",
    "df_train = df_train.dropna(subset=['num_beds'])\n",
    "df_train = df_train.dropna(subset=['num_baths'])\n",
    "\n",
    "# DBSCAN using beds to baths ratio\n",
    "df_train['beds_to_baths'] = df_train['num_beds'] / df_train['num_baths']\n",
    "sk_clustering_iris = DBSCAN(eps=0.5, min_samples=5).fit(df_train[['beds_to_baths']])\n",
    "sk_noise_iris = np.argwhere(sk_clustering_iris.labels_ < 0).squeeze()\n",
    "sk_noise_iris.sort()\n",
    "\n",
    "for i in sk_noise_iris:\n",
    "    df_train = df_train.drop(i)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "# DBSCAN using baths to beds ratio\n",
    "df_train['baths_to_beds'] = df_train['num_baths'] / df_train['num_beds']\n",
    "sk_clustering_iris = DBSCAN(eps=0.5, min_samples=5).fit(df_train[['baths_to_beds']])\n",
    "sk_noise_iris = np.argwhere(sk_clustering_iris.labels_ < 0).squeeze()\n",
    "sk_noise_iris.sort()\n",
    "\n",
    "for i in sk_noise_iris:\n",
    "    df_train = df_train.drop(i)\n",
    "    df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete the data with unreasonable size\n",
    "# DBSCAN using size to rooms ratio\n",
    "df_train['sqft_to_rooms'] = df_train['size_sqft'] / (df_train['num_beds'] + df_train['num_baths'])\n",
    "sk_clustering_iris = DBSCAN(eps=50, min_samples=5).fit(df_train[['sqft_to_rooms']])\n",
    "sk_noise_iris = np.argwhere(sk_clustering_iris.labels_ < 0).squeeze()\n",
    "sk_noise_iris.sort()\n",
    "\n",
    "for i in sk_noise_iris:\n",
    "    df_train = df_train.drop(i)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# DBSCAN using rooms to size ratio\n",
    "df_train['rooms_to_sqft'] = (df_train['num_beds'] + df_train['num_baths']) / df_train['size_sqft']\n",
    "sk_clustering_iris = DBSCAN(eps=0.0005, min_samples=5).fit(df_train[['rooms_to_sqft']])\n",
    "sk_noise_iris = np.argwhere(sk_clustering_iris.labels_ < 0).squeeze()\n",
    "sk_noise_iris.sort()\n",
    "\n",
    "for i in sk_noise_iris:\n",
    "    df_train = df_train.drop(i)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "df_train.drop(['rooms_to_sqft', 'sqft_to_rooms', 'baths_to_beds', 'beds_to_baths'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb31b51-f291-4716-bcbe-610be322f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use new feature price_per_sqft to detect unreasonable price\n",
    "df_train[\"price_per_sqft\"] = df_train[\"price\"]/df_train[\"size_sqft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a9376-cf98-43a6-b864-53936af4c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(df_train[\"price_per_sqft\"].describe())\n",
    "sns.boxplot(y = df_train[\"price_per_sqft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe7eb8-2fbd-434b-8ff2-0fb9a06fd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unreasonable data based on 3-sigma rules\n",
    "while True:\n",
    "    mean = np.mean(df_train[\"price_per_sqft\"])\n",
    "    std = np.std(df_train[\"price_per_sqft\"])\n",
    "    high = mean + 3*std\n",
    "    low = mean - 3*std\n",
    "    if ((df_train[\"price_per_sqft\"]>low).all() and (df_train[\"price_per_sqft\"]<high).all()) == True:\n",
    "        break\n",
    "    else:\n",
    "        df_train = df_train[df_train[\"price_per_sqft\"] > low]\n",
    "        df_train = df_train[df_train[\"price_per_sqft\"] < high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf2049-5b6c-46b2-8183-3fb928d29c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"price_per_sqft\"].describe())\n",
    "sns.boxplot(y = df_train[\"price_per_sqft\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919a2bb-760e-4c37-8f61-e430681c1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a boundary to remove the unreasonably small data\n",
    "fig, ax =plt.subplots(1,3,constrained_layout=True, figsize=(12, 3))\n",
    "s1=sns.distplot(df_train[\"price_per_sqft\"], ax=ax[0])\n",
    "s1.set_title(\"all data\")\n",
    "s2=sns.distplot(df_train[df_train[\"price_per_sqft\"]<1000][\"price_per_sqft\"], ax=ax[1])\n",
    "s2.set_title(\"<1000\")\n",
    "s3=sns.distplot(df_train[df_train[\"price_per_sqft\"]<400][\"price_per_sqft\"], ax=ax[2])\n",
    "s3.set_title(\"<400\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf81e7-cafe-4d2d-a4b0-88d6b95aa86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unreasonable data still exists, and drop them.\n",
    "df_train = df_train[df_train[\"price_per_sqft\"] > 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c28d1-58b5-4a41-9816-c2060c3f09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature num_rooms\n",
    "df_train[\"num_rooms\"] = df_train[\"num_beds\"] + df_train[\"num_baths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697053bb-49e1-405c-9b9d-35160cb3fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9b6bb-4f68-4fac-a914-37bcd0b40500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdb = df_train[df_train['property_type'] == 'hdb'].loc[:, ['lat', 'lng']]\n",
    "df_hdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af85bf-6ede-48b5-b2a9-ab993937edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hdb = df_hdb.groupby(['lat', 'lng']).size().reset_index(name='counts')\n",
    "fig = px.density_mapbox(df_hdb, lat='lat', lon='lng', z='counts',\n",
    "                        mapbox_style=\"stamen-terrain\")\n",
    " \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721d644-1efd-4511-b47f-0a1ef23e5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condo = df_train[df_train['property_type'] == 'condo'].loc[:, ['lat', 'lng']]\n",
    "df_condo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2d0f5-ee21-4df0-8018-7b534c58618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_condo = df_condo.groupby(['lat', 'lng']).size().reset_index(name='counts')\n",
    "fig = px.density_mapbox(df_condo, lat='lat', lon='lng', z='counts',\n",
    "                        mapbox_style=\"stamen-terrain\")\n",
    " \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250c9ef-a71a-4685-ab22-8560458d71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_hdb = df_train[df_train['property_type'] == 'hdb'].loc[:, ['lat', 'lng']]\n",
    "\n",
    "# Normalize the dataset\n",
    "for i in list(df_train_hdb.columns):\n",
    "    df_train_hdb[i] = (df_train_hdb[i]-min(df_train_hdb[i]))/(max(df_train_hdb[i]) - min(df_train_hdb[i]))\n",
    "    \n",
    "\n",
    "SSE = []\n",
    "for cluster in range(1,20):\n",
    "    kmeans = KMeans(n_clusters = cluster, init='k-means++')\n",
    "    kmeans.fit(df_train_hdb)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "    \n",
    "frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(frame['Cluster'], frame['SSE'], marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8303b0b-e089-4513-b438-36e9c948ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 4, init='k-means++')\n",
    "kmeans.fit(df_train_hdb)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "df_train_hdb = df_train[df_train['property_type'] == 'hdb'].loc[:, ['lat', 'lng']]\n",
    "\n",
    "df_train_hdb['labels'] = labels\n",
    "\n",
    "df_train_hdb = df_train_hdb.drop_duplicates(subset=['lat', 'lng'])\n",
    "\n",
    "fig = px.scatter_mapbox(df_train_hdb, lat='lat', lon='lng', color='labels',\n",
    "                        mapbox_style=\"open-street-map\")\n",
    " \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e23f8-c062-4833-bb18-5c2268b4a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_condo = df_train[df_train['property_type'] == 'condo'].loc[:, ['lat', 'lng']]\n",
    "\n",
    "# Normalize the dataset\n",
    "for i in list(df_train_condo.columns):\n",
    "    df_train_condo[i] = (df_train_condo[i]-min(df_train_condo[i]))/(max(df_train_condo[i]) - min(df_train_condo[i]))\n",
    "    \n",
    "SSE = []\n",
    "for cluster in range(1,20):\n",
    "    kmeans = KMeans(n_clusters = cluster, init='k-means++')\n",
    "    kmeans.fit(df_train_condo)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "    \n",
    "frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(frame['Cluster'], frame['SSE'], marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27430c40-e2a2-4fed-9876-f0abdaf0c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 4, init='k-means++')\n",
    "kmeans.fit(df_train_condo)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "df_train_condo = df_train[df_train['property_type'] == 'condo'].loc[:, ['lat', 'lng']]\n",
    "\n",
    "df_train_condo['labels'] = labels\n",
    "\n",
    "df_train_condo = df_train_condo.drop_duplicates(subset=['lat', 'lng'])\n",
    "\n",
    "fig = px.scatter_mapbox(df_train_condo, lat='lat', lon='lng', color='labels',\n",
    "                        mapbox_style=\"open-street-map\")\n",
    " \n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dcefb0-ec0f-4a84-ad91-71a39f98480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "train = copy.deepcopy(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4303c7-a05e-4462-ae68-809a05aa0608",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.groupby(\"property_type\").mean()\n",
    "temp = temp.sort_values(by=\"price\",ascending=True)\n",
    "ax_order = temp.index.tolist()\n",
    "fig, ax =plt.subplots(1,2,constrained_layout=True, figsize=(12, 5))\n",
    "s1 = sns.barplot(y=\"price\", x=\"property_type\", data=train, ax=ax[0])\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation = 80)\n",
    "s2 = sns.barplot(y=\"price\", x=\"property_type\", data=train, order=ax_order, ax=ax[1])\n",
    "s2.set_xticklabels(s2.get_xticklabels(),rotation = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e6679-e851-40f8-a816-10782413a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding property_type based on the visualization above\n",
    "train = train.replace([\"hdb\", \"hdb executive\", \"walk-up\", \"executive condo\", \"shophouse\"],[0,0,0,0,0])\n",
    "train = train.replace([\"condo\", \"apartment\", \"landed\", \"terraced house\", \"cluster house\"],[1,1,1,1,1])\n",
    "train = train.replace([\"townhouse\", \"corner terrace\", \"good class bungalow\", \"semi-detached house\"],[2, 2, 2, 2])\n",
    "train = train.replace([\"bungalow\"], [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f33e39-e3bb-40bf-8594-6575f3d19dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the tenure\n",
    "train = train.replace([\"99-year leasehold\", \"110-year leasehold\", \"103-year leasehold\", \"102-year leasehold\", \"100-year leasehold\"],[0,0,0,0,0])\n",
    "train = train.replace([\"999-year leasehold\", \"946-year leasehold\", \"956-year leasehold\", \"929-year leasehold\", \"947-year leasehold\"],[1,1,1,1,1])\n",
    "train = train.replace([\"freehold\"],[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04932b6b-6842-45a5-aa23-77f26abe68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the built_year\n",
    "#discrete\n",
    "#0-1963-1970\n",
    "#1-1971-1990\n",
    "#2-1991-2005\n",
    "#3-2006-2020\n",
    "#4-2021-2028\n",
    "for i in range(train.shape[0]):\n",
    "    if train.iloc[i,6]<=1970:\n",
    "        train.iloc[i,6]=0\n",
    "    if train.iloc[i,6]<=1990 and train.iloc[i,6]>=1971:\n",
    "        train.iloc[i,6]=1\n",
    "    if train.iloc[i,6]>=1991 and train.iloc[i,6]<=2005:\n",
    "        train.iloc[i,6]=2\n",
    "    if train.iloc[i,6]>=2006 and train.iloc[i,6]<=2020:\n",
    "        train.iloc[i,6]=3\n",
    "    if train.iloc[i,6]>=2021:\n",
    "        train.iloc[i,6]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99f8ab-2172-4cf7-b002-48a47a455053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the mininum distance, to deal with the auxilary data.\n",
    "def min_dist(lat, lng, df):\n",
    "    return min(np.sqrt((df[\"lat\"]-lat)**2+(df[\"lng\"]-lng)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c84fa-8e49-4a09-970d-7d19fabe4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "commercial_centres = pd.read_csv(r\"auxiliary-data\\sg-commerical-centres.csv\")\n",
    "mrt_stations = pd.read_csv(r\"auxiliary-data\\sg-mrt-stations.csv\")\n",
    "primary_schools = pd.read_csv(r\"auxiliary-data\\sg-primary-schools.csv\")\n",
    "secondary_schools = pd.read_csv(r\"auxiliary-data\\sg-secondary-schools.csv\")\n",
    "shopping_malls = pd.read_csv(r\"auxiliary-data\\sg-shopping-malls.csv\")\n",
    "subzones = pd.read_csv(r\"auxiliary-data\\sg-subzones.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58966db7-ee42-453e-b5be-506cef49c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the distance of nearest mrt station, primary school and shopping mall.\n",
    "min_dist_commercial = []\n",
    "min_dist_mrt = []\n",
    "min_dist_pri = []\n",
    "min_dist_sec = []\n",
    "min_dist_mall = []\n",
    "for i in range(train.shape[0]):\n",
    "    min_dist_commercial.append(min_dist(train[\"lat\"][i],train[\"lng\"][i],commercial_centres))\n",
    "    min_dist_mrt.append(min_dist(train[\"lat\"][i],train[\"lng\"][i],mrt_stations))\n",
    "    min_dist_pri.append(min_dist(train[\"lat\"][i],train[\"lng\"][i],primary_schools))\n",
    "    min_dist_sec.append(min_dist(train[\"lat\"][i],train[\"lng\"][i],secondary_schools))\n",
    "    min_dist_mall.append(min_dist(train[\"lat\"][i],train[\"lng\"][i],shopping_malls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08b03f-c9f5-4215-9e62-28040a961add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train[\"dist_mrt\"] = (np.array(min_dist_mrt)-min(min_dist_mrt))/(max(min_dist_mrt)-min(min_dist_mrt))\n",
    "train[\"dist_pri\"] = (np.array(min_dist_pri)-min(min_dist_pri))/(max(min_dist_pri)-min(min_dist_pri))\n",
    "train[\"dist_mall\"] = (np.array(min_dist_mall)-min(min_dist_mall))/(max(min_dist_mall)-min(min_dist_mall))\n",
    "train[\"dist_commercial\"] = (np.array(min_dist_commercial)-min(min_dist_commercial))/(max(min_dist_commercial)-min(min_dist_commercial))\n",
    "train[\"dist_sec\"] = (np.array(min_dist_sec)-min(min_dist_sec))/(max(min_dist_sec)-min(min_dist_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577f462-82f6-4f5d-a8c2-1ffb5351892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.groupby(\"subzone\").mean()\n",
    "temp = temp.sort_values(by=\"price\",ascending=True)\n",
    "ax_order = temp.index.tolist()\n",
    "fig, ax =plt.subplots(2, 1,constrained_layout=True, figsize=(60, 40))\n",
    "s1 = sns.barplot(y=\"price\", x=\"subzone\", data=train, ax=ax[0])\n",
    "s1.set_xticklabels(s1.get_xticklabels(),rotation = 80)\n",
    "s2 = sns.barplot(y=\"price\", x=\"subzone\", data=train, order=ax_order, ax=ax[1])\n",
    "s2.set_xticklabels(s2.get_xticklabels(),rotation = 80)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.xlabel(\"Subzone\", fontsize = 30)\n",
    "plt.ylabel(\"Average Price\", fontsize = 30)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.xlabel(\"Subzone\", fontsize = 30)\n",
    "plt.ylabel(\"Average Price\", fontsize = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbe0a2-5a87-4e51-ae5d-7793d4fa0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the average price of all the houses in a subzone to encode the feature subzone\n",
    "for i in list(set(train[\"subzone\"])):\n",
    "    temp = train[train[\"subzone\"] == i]\n",
    "    train = train.replace(i, np.mean(temp[\"price\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0cae5-f960-4c60-a169-49fab515d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a5515-f0cb-4520-ab92-d88eb789d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hdb = train[train['property_type'] == 0]\n",
    "\n",
    "train_hdb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a2627-8b8b-408d-bf5a-bd664bf80dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hdb = train_hdb.drop(columns=['listing_id', 'title', 'address', 'property_name', 'property_type', 'num_beds', 'num_baths', 'floor_level', 'furnishing', 'available_unit_types', \n",
    "                        'total_num_units', 'property_details_url', 'lat', 'lng', 'elevation','planning_area', 'lease_end_year', 'tenure'])\n",
    "\n",
    "train_hdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24614103-d8d9-4126-afa8-23d58fa07152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "for i in range(6, 11):\n",
    "    train_hdb.iloc[:, i] = 1 / train_hdb.iloc[:, i]\n",
    "\n",
    "train_hdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729c120-384d-4f8f-8f17-1a2e749328d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "for i in list(train_hdb.columns):\n",
    "    train_hdb[i] = (train_hdb[i]-min(train_hdb[i]))/(max(train_hdb[i]) - min(train_hdb[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee91297-d491-48d1-9dfb-dcb77787cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hdb.to_csv('train_hdb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51190e4-61bc-4a06-8af9-3dae9ae1d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE = []\n",
    "for cluster in range(1,20):\n",
    "    kmeans = KMeans(n_clusters = cluster, init='k-means++')\n",
    "    kmeans.fit(train_hdb)\n",
    "    SSE.append(kmeans.inertia_)\n",
    "    \n",
    "frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(frame['Cluster'], frame['SSE'], marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3580b92-4e38-4276-939e-98f422bc5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5, init='k-means++')\n",
    "kmeans.fit(train_hdb)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326c185-6502-4925-b396-5c8ee667d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = train_hdb\n",
    "\n",
    "cluster['labels'] = labels\n",
    "\n",
    "cluster = cluster.groupby(by=['labels']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95290bd6-bd54-4625-b92f-813abc58b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "for i in range(0, 11):\n",
    "    cluster.iloc[:, i] = (cluster.iloc[:, i] - cluster.iloc[:, i].min()) / (cluster.iloc[:, i].max() - cluster.iloc[:, i].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b26358-8e5d-4c70-96c5-e0ea1103a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c66259-7e8a-43c9-a591-6666aa553eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['built_year', 'size_sqft', 'subzone', 'price', 'price_per_sqft', 'num_rooms', 'dist_mrt', 'dist_pri', 'dist_mall', 'dist_commercial', 'dist_sec']\n",
    "fig = go.Figure()\n",
    "\n",
    "for index, row in cluster.iterrows():\n",
    "    if index == 4:\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r = [row['built_year'], row['size_sqft'], row['subzone'], row['price'], row['price_per_sqft'], row['num_rooms'], row['dist_mrt'], row['dist_pri'], row['dist_mall'], row['dist_commercial'], row['dist_sec']],\n",
    "          theta=categories,\n",
    "          fill='toself',\n",
    "          name='Cluster {}'.format(index)\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True,\n",
    "      # range=[0, 5]\n",
    "    )),\n",
    "  showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
